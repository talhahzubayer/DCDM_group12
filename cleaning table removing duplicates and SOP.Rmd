---
title: "data_cleaning"
output: html_document
date: "2025-11-10"
---

```{r}
getwd()
setwd("/Users/sabrinasaidoune/Desktop/Group12/")
dir()
```

```{r}

folder_path <- "/Users/sabrinasaidoune/Desktop/Group12/"

# Load the original dataset
original_file <- file.path(folder_path, "data_table_combined.csv")
data <- read.csv("/Users/sabrinasaidoune/Desktop/Group12/data_table_combined.csv", stringsAsFactors = FALSE)


# Identify duplicate rows ----
duplicate_rows <- duplicated(data)

# split data into unique and duplicate subsets only keeping the first occurrence of each row
cleaned_data <- data[!duplicate_rows, ]

# Keep only the duplicated rows (excluding the first occurrence)
removed_duplicates <- data[duplicate_rows, ]

write.csv(cleaned_data, file.path(folder_path, "data_table_noDuplicates.csv"), row.names = FALSE)

# Save the removed duplicate rows
write.csv(removed_duplicates, file.path(folder_path, "data_table_duplicatesRemoved.csv"), row.names = FALSE)


```


```{r}

# Data Cleaning Script (SOP Rules)


# Set folder path
folder_path <- "/Users/sabrinasaidoune/Desktop/Group12/"

# Load the dataset
input_file <- file.path(folder_path, "data_table_noDuplicates.csv")
data <- read.csv(input_file, stringsAsFactors = FALSE)

# Create a copy for cleaning
cleaned_data <- data

# Create a vector to track valid rows.
valid_rows <- rep(TRUE, nrow(cleaned_data))

# check string length ranges
check_length <- function(column, min_len, max_len) {
  nchar_val <- nchar(as.character(column))
  return(nchar_val >= min_len & nchar_val <= max_len)
}

# Apply SOP  rules

valid_rows <- valid_rows & (nchar(as.character(cleaned_data$analysis_id)) == 15)
valid_rows <- valid_rows & check_length(cleaned_data$gene_accession_id, 9, 11)
valid_rows <- valid_rows & check_length(cleaned_data$gene_symbol, 1, 13)
valid_rows <- valid_rows & check_length(cleaned_data$mouse_strain, 3, 5)
valid_rows <- valid_rows & check_length(cleaned_data$mouse_life_stage, 4, 17)
valid_rows <- valid_rows & check_length(cleaned_data$parameter_id, 15, 20)
valid_rows <- valid_rows & check_length(cleaned_data$parameter_name, 2, 74)

# Ensure pvalue is numeric and within [0, 1]
cleaned_data$pvalue <- suppressWarnings(as.numeric(cleaned_data$pvalue))
valid_rows <- valid_rows & !is.na(cleaned_data$pvalue)
valid_rows <- valid_rows & (cleaned_data$pvalue >= 0 & cleaned_data$pvalue <= 1)

# Split into clean and removed data

final_cleaned <- cleaned_data[valid_rows, ]
removed_rows <- cleaned_data[!valid_rows, ]


write.csv(final_cleaned, file.path(folder_path, "data_table_cleaned_SOP.csv"), row.names = FALSE)
write.csv(removed_rows, file.path(folder_path, "data_table_removed_SOP.csv"), row.names = FALSE)


```

